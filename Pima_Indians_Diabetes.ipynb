{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pima_Indians_Diabetes.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ankitchimaniya/Machine-Learning-Lab/blob/master/Pima_Indians_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVS8Vp-ntc4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "7c9510ad-b8ba-4ca7-be41-cdc481187f8d"
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S21PTNEFuB-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset\n",
        "dataset = loadtxt('/content/pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmcPosykvTrX",
        "colab_type": "code",
        "outputId": "522a1c89-0a6d-4a16-94c3-e0cddae958aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# load the dataset\n",
        "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(90, input_dim=8, activation='tanh'))\n",
        "model.add(Dense(90, activation='tanh'))\n",
        "model.add(Dense(50, activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=150, batch_size=40)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "768/768 [==============================] - 1s 868us/step - loss: 0.7086 - acc: 0.6068\n",
            "Epoch 2/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.6123 - acc: 0.6654\n",
            "Epoch 3/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.5901 - acc: 0.6784\n",
            "Epoch 4/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.5657 - acc: 0.6979\n",
            "Epoch 5/150\n",
            "768/768 [==============================] - 0s 38us/step - loss: 0.5614 - acc: 0.7018\n",
            "Epoch 6/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.5565 - acc: 0.6992\n",
            "Epoch 7/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.5496 - acc: 0.7148\n",
            "Epoch 8/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.5357 - acc: 0.7148\n",
            "Epoch 9/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.5319 - acc: 0.7253\n",
            "Epoch 10/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.5254 - acc: 0.7357\n",
            "Epoch 11/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.5342 - acc: 0.7109\n",
            "Epoch 12/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.5408 - acc: 0.7357\n",
            "Epoch 13/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.5236 - acc: 0.7292\n",
            "Epoch 14/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.5251 - acc: 0.7279\n",
            "Epoch 15/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.5138 - acc: 0.7331\n",
            "Epoch 16/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.5048 - acc: 0.7474\n",
            "Epoch 17/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.5066 - acc: 0.7422\n",
            "Epoch 18/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.5273 - acc: 0.7305\n",
            "Epoch 19/150\n",
            "768/768 [==============================] - 0s 64us/step - loss: 0.4999 - acc: 0.7435\n",
            "Epoch 20/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.5093 - acc: 0.7409\n",
            "Epoch 21/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.5012 - acc: 0.7500\n",
            "Epoch 22/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.5044 - acc: 0.7461\n",
            "Epoch 23/150\n",
            "768/768 [==============================] - 0s 51us/step - loss: 0.4979 - acc: 0.7487\n",
            "Epoch 24/150\n",
            "768/768 [==============================] - 0s 56us/step - loss: 0.4969 - acc: 0.7461\n",
            "Epoch 25/150\n",
            "768/768 [==============================] - 0s 53us/step - loss: 0.5191 - acc: 0.7435\n",
            "Epoch 26/150\n",
            "768/768 [==============================] - 0s 48us/step - loss: 0.4821 - acc: 0.7630\n",
            "Epoch 27/150\n",
            "768/768 [==============================] - 0s 49us/step - loss: 0.4873 - acc: 0.7552\n",
            "Epoch 28/150\n",
            "768/768 [==============================] - 0s 49us/step - loss: 0.4790 - acc: 0.7643\n",
            "Epoch 29/150\n",
            "768/768 [==============================] - 0s 49us/step - loss: 0.4692 - acc: 0.7747\n",
            "Epoch 30/150\n",
            "768/768 [==============================] - 0s 50us/step - loss: 0.4668 - acc: 0.7826\n",
            "Epoch 31/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.4791 - acc: 0.7630\n",
            "Epoch 32/150\n",
            "768/768 [==============================] - 0s 52us/step - loss: 0.4700 - acc: 0.7682\n",
            "Epoch 33/150\n",
            "768/768 [==============================] - 0s 57us/step - loss: 0.5066 - acc: 0.7383\n",
            "Epoch 34/150\n",
            "768/768 [==============================] - 0s 48us/step - loss: 0.4887 - acc: 0.7435\n",
            "Epoch 35/150\n",
            "768/768 [==============================] - 0s 50us/step - loss: 0.4664 - acc: 0.7760\n",
            "Epoch 36/150\n",
            "768/768 [==============================] - 0s 50us/step - loss: 0.4710 - acc: 0.7617\n",
            "Epoch 37/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4614 - acc: 0.7826\n",
            "Epoch 38/150\n",
            "768/768 [==============================] - 0s 53us/step - loss: 0.4733 - acc: 0.7708\n",
            "Epoch 39/150\n",
            "768/768 [==============================] - 0s 49us/step - loss: 0.4750 - acc: 0.7565\n",
            "Epoch 40/150\n",
            "768/768 [==============================] - 0s 57us/step - loss: 0.4584 - acc: 0.7799\n",
            "Epoch 41/150\n",
            "768/768 [==============================] - 0s 53us/step - loss: 0.4503 - acc: 0.7878\n",
            "Epoch 42/150\n",
            "768/768 [==============================] - 0s 50us/step - loss: 0.4677 - acc: 0.7708\n",
            "Epoch 43/150\n",
            "768/768 [==============================] - 0s 50us/step - loss: 0.4696 - acc: 0.7682\n",
            "Epoch 44/150\n",
            "768/768 [==============================] - 0s 50us/step - loss: 0.4696 - acc: 0.7760\n",
            "Epoch 45/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.4405 - acc: 0.7799\n",
            "Epoch 46/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4472 - acc: 0.7799\n",
            "Epoch 47/150\n",
            "768/768 [==============================] - 0s 49us/step - loss: 0.4469 - acc: 0.7891\n",
            "Epoch 48/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4467 - acc: 0.7747\n",
            "Epoch 49/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4347 - acc: 0.7865\n",
            "Epoch 50/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.4569 - acc: 0.7682\n",
            "Epoch 51/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.4552 - acc: 0.7773\n",
            "Epoch 52/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.4608 - acc: 0.7773\n",
            "Epoch 53/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.4295 - acc: 0.7982\n",
            "Epoch 54/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.4320 - acc: 0.7904\n",
            "Epoch 55/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.4456 - acc: 0.7839\n",
            "Epoch 56/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.4197 - acc: 0.8021\n",
            "Epoch 57/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.4257 - acc: 0.7904\n",
            "Epoch 58/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.4289 - acc: 0.7943\n",
            "Epoch 59/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.4351 - acc: 0.7943\n",
            "Epoch 60/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.4289 - acc: 0.7982\n",
            "Epoch 61/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.4186 - acc: 0.8099\n",
            "Epoch 62/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.4338 - acc: 0.7891\n",
            "Epoch 63/150\n",
            "768/768 [==============================] - 0s 47us/step - loss: 0.4169 - acc: 0.8008\n",
            "Epoch 64/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.4117 - acc: 0.8099\n",
            "Epoch 65/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.4234 - acc: 0.7956\n",
            "Epoch 66/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.4335 - acc: 0.7865\n",
            "Epoch 67/150\n",
            "768/768 [==============================] - 0s 51us/step - loss: 0.4456 - acc: 0.7799\n",
            "Epoch 68/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.4156 - acc: 0.8047\n",
            "Epoch 69/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.4095 - acc: 0.7982\n",
            "Epoch 70/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3975 - acc: 0.8138\n",
            "Epoch 71/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.3882 - acc: 0.8216\n",
            "Epoch 72/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.4006 - acc: 0.8060\n",
            "Epoch 73/150\n",
            "768/768 [==============================] - 0s 49us/step - loss: 0.3897 - acc: 0.8190\n",
            "Epoch 74/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.4263 - acc: 0.7878\n",
            "Epoch 75/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.4034 - acc: 0.8099\n",
            "Epoch 76/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4020 - acc: 0.8021\n",
            "Epoch 77/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.4132 - acc: 0.8073\n",
            "Epoch 78/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4091 - acc: 0.8047\n",
            "Epoch 79/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.4042 - acc: 0.8047\n",
            "Epoch 80/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.4092 - acc: 0.8021\n",
            "Epoch 81/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4032 - acc: 0.8021\n",
            "Epoch 82/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3816 - acc: 0.8203\n",
            "Epoch 83/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4022 - acc: 0.7930\n",
            "Epoch 84/150\n",
            "768/768 [==============================] - 0s 47us/step - loss: 0.3969 - acc: 0.8177\n",
            "Epoch 85/150\n",
            "768/768 [==============================] - 0s 48us/step - loss: 0.4051 - acc: 0.8034\n",
            "Epoch 86/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3966 - acc: 0.8138\n",
            "Epoch 87/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3806 - acc: 0.8073\n",
            "Epoch 88/150\n",
            "768/768 [==============================] - 0s 47us/step - loss: 0.3790 - acc: 0.8203\n",
            "Epoch 89/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3727 - acc: 0.8242\n",
            "Epoch 90/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3748 - acc: 0.8346\n",
            "Epoch 91/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3744 - acc: 0.8242\n",
            "Epoch 92/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.3928 - acc: 0.8047\n",
            "Epoch 93/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3977 - acc: 0.8138\n",
            "Epoch 94/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.4072 - acc: 0.8112\n",
            "Epoch 95/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3991 - acc: 0.8034\n",
            "Epoch 96/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3840 - acc: 0.8021\n",
            "Epoch 97/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3715 - acc: 0.8216\n",
            "Epoch 98/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3546 - acc: 0.8307\n",
            "Epoch 99/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3672 - acc: 0.8255\n",
            "Epoch 100/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3628 - acc: 0.8307\n",
            "Epoch 101/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.3696 - acc: 0.8268\n",
            "Epoch 102/150\n",
            "768/768 [==============================] - 0s 48us/step - loss: 0.3792 - acc: 0.8229\n",
            "Epoch 103/150\n",
            "768/768 [==============================] - 0s 52us/step - loss: 0.3473 - acc: 0.8437\n",
            "Epoch 104/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.3640 - acc: 0.8307\n",
            "Epoch 105/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.3782 - acc: 0.8138\n",
            "Epoch 106/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.3534 - acc: 0.8359\n",
            "Epoch 107/150\n",
            "768/768 [==============================] - 0s 50us/step - loss: 0.3667 - acc: 0.8346\n",
            "Epoch 108/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.3524 - acc: 0.8346\n",
            "Epoch 109/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3575 - acc: 0.8346\n",
            "Epoch 110/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.3444 - acc: 0.8385\n",
            "Epoch 111/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3389 - acc: 0.8359\n",
            "Epoch 112/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3420 - acc: 0.8438\n",
            "Epoch 113/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.3323 - acc: 0.8398\n",
            "Epoch 114/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.3466 - acc: 0.8372\n",
            "Epoch 115/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3585 - acc: 0.8320\n",
            "Epoch 116/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3460 - acc: 0.8372\n",
            "Epoch 117/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.3440 - acc: 0.8372\n",
            "Epoch 118/150\n",
            "768/768 [==============================] - 0s 39us/step - loss: 0.3461 - acc: 0.8281\n",
            "Epoch 119/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3593 - acc: 0.8333\n",
            "Epoch 120/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3393 - acc: 0.8411\n",
            "Epoch 121/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3382 - acc: 0.8333\n",
            "Epoch 122/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3993 - acc: 0.8099\n",
            "Epoch 123/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3548 - acc: 0.8255\n",
            "Epoch 124/150\n",
            "768/768 [==============================] - 0s 55us/step - loss: 0.3458 - acc: 0.8333\n",
            "Epoch 125/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.3413 - acc: 0.8359\n",
            "Epoch 126/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3476 - acc: 0.8333\n",
            "Epoch 127/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.3233 - acc: 0.8607\n",
            "Epoch 128/150\n",
            "768/768 [==============================] - 0s 45us/step - loss: 0.3415 - acc: 0.8307\n",
            "Epoch 129/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.3441 - acc: 0.8385\n",
            "Epoch 130/150\n",
            "768/768 [==============================] - 0s 44us/step - loss: 0.3307 - acc: 0.8516\n",
            "Epoch 131/150\n",
            "768/768 [==============================] - 0s 46us/step - loss: 0.3720 - acc: 0.8190\n",
            "Epoch 132/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3438 - acc: 0.8255\n",
            "Epoch 133/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3261 - acc: 0.8529\n",
            "Epoch 134/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.3203 - acc: 0.8516\n",
            "Epoch 135/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.3140 - acc: 0.8529\n",
            "Epoch 136/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3356 - acc: 0.8477\n",
            "Epoch 137/150\n",
            "768/768 [==============================] - 0s 39us/step - loss: 0.3212 - acc: 0.8438\n",
            "Epoch 138/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3830 - acc: 0.8346\n",
            "Epoch 139/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.3224 - acc: 0.8398\n",
            "Epoch 140/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3193 - acc: 0.8477\n",
            "Epoch 141/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3025 - acc: 0.8607\n",
            "Epoch 142/150\n",
            "768/768 [==============================] - 0s 43us/step - loss: 0.3163 - acc: 0.8555\n",
            "Epoch 143/150\n",
            "768/768 [==============================] - 0s 42us/step - loss: 0.3173 - acc: 0.8385\n",
            "Epoch 144/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3110 - acc: 0.8594\n",
            "Epoch 145/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3293 - acc: 0.8581\n",
            "Epoch 146/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3128 - acc: 0.8516\n",
            "Epoch 147/150\n",
            "768/768 [==============================] - 0s 49us/step - loss: 0.3310 - acc: 0.8503\n",
            "Epoch 148/150\n",
            "768/768 [==============================] - 0s 40us/step - loss: 0.3220 - acc: 0.8451\n",
            "Epoch 149/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3300 - acc: 0.8503\n",
            "Epoch 150/150\n",
            "768/768 [==============================] - 0s 41us/step - loss: 0.3331 - acc: 0.8438\n",
            "768/768 [==============================] - 0s 63us/step\n",
            "Accuracy: 84.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v24i_ZZvUJC",
        "colab_type": "text"
      },
      "source": [
        "The variables can be summarized as follows:\n",
        "\n",
        "Input Variables (X):\n",
        "\n",
        "Number of times pregnant\n",
        "Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "Diastolic blood pressure (mm Hg)\n",
        "Triceps skin fold thickness (mm)\n",
        "2-Hour serum insulin (mu U/ml)\n",
        "Body mass index (weight in kg/(height in m)^2)\n",
        "Diabetes pedigree function\n",
        "Age (years)\n",
        "Output Variables (y):\n",
        "\n",
        "Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMtVBy_uFD2K",
        "colab_type": "code",
        "outputId": "20727261-357e-42b6-d4ef-80f718fd0340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"/content/pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "#plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWeklEQVR4nO3dfbRddX3n8feHEIxKBJvEqRIU1KCm\n1greota2YqGzEEvQ2lGwaLEOtCo+tOrUVkdZdB7qWO2MlhaitSIiDzJKM4oyQFHHB5AgiIKiKRW5\n+EAMDyIaHuQ7f+yd5nC52dm5ZN97cvN+rXXXOnvv397ne3/r3vM5e//O/p1UFZIkbckuc12AJGm8\nGRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoV2Kkk+mOS/9Gz7nSSHDF2TNO4MCklSJ4NC2gEl2XWu\na9DOw6DQ2Gkv+bwpyVVJ7kjyD0n+XZJPJbk9yYVJHj7SflWSq5PcmuQzSZ40sm3/JF9p9zsLWDTl\nuX4nyZXtvl9M8pSeNT4vyRVJfpzkhiQnTNn+6+3xbm23H9Ouf3CSdyW5PsltST7frjsoyeQ0/XBI\n+/iEJOck+XCSHwPHJDkwyZfa5/h+kr9NstvI/r+U5IIkNyf5YZK/SPKLSX6aZMlIuwOSrE+ysM/v\nrp2PQaFx9ULgt4H9gMOBTwF/ASyj+bt9LUCS/YAzgNe3284D/k+S3doXzXOB04BfAD7aHpd23/2B\nDwB/BCwBTgHWJHlQj/ruAF4G7Ak8D3hlkue3x31MW+9725qeClzZ7vfXwNOAX2tr+k/AvT375Ajg\nnPY5Twd+DvwJsBR4JnAw8Kq2hsXAhcCngUcBjwcuqqofAJ8BXjRy3JcCZ1bV3T3r0E7GoNC4em9V\n/bCqbgT+H3BpVV1RVRuBjwP7t+1eDHyyqi5oX+j+GngwzQvxM4CFwP+sqrur6hzgspHnOA44paou\nraqfV9WpwJ3tfp2q6jNV9bWqureqrqIJq2e3m18CXFhVZ7TPu6GqrkyyC/CHwOuq6sb2Ob9YVXf2\n7JMvVdW57XP+rKour6pLquqeqvoOTdBtquF3gB9U1buqamNV3V5Vl7bbTgWOBkiyADiKJkylaRkU\nGlc/HHn8s2mWd28fPwq4ftOGqroXuAHYq912Y9135svrRx4/BnhDe+nm1iS3Anu3+3VK8vQkF7eX\nbG4D/pjmnT3tMf5lmt2W0lz6mm5bHzdMqWG/JJ9I8oP2ctR/61EDwD8BK5PsS3PWdltVfXmGNWkn\nYFBoR/c9mhd8AJKE5kXyRuD7wF7tuk0ePfL4BuC/VtWeIz8PqaozejzvR4A1wN5VtQdwMrDpeW4A\nHjfNPj8CNm5h2x3AQ0Z+jwU0l61GTZ3q+e+BbwIrquphNJfmRmt47HSFt2dlZ9OcVbwUzya0FQaF\ndnRnA89LcnA7GPsGmstHXwS+BNwDvDbJwiS/Cxw4su/7gD9uzw6S5KHtIPXiHs+7GLi5qjYmOZDm\nctMmpwOHJHlRkl2TLEny1PZs5wPAu5M8KsmCJM9sx0S+BSxqn38h8FZga2Mli4EfAz9J8kTglSPb\nPgE8MsnrkzwoyeIkTx/Z/iHgGGAVBoW2wqDQDq2qrqV5Z/xemnfshwOHV9VdVXUX8Ls0L4g304xn\nfGxk37XAscDfArcA69q2fbwKODHJ7cDbaAJr03G/CxxGE1o30wxk/0q7+Y3A12jGSm4G3gHsUlW3\ntcd8P83Z0B3AfT4FNY030gTU7TShd9ZIDbfTXFY6HPgB8G3gOSPbv0AziP6Vqhq9HCfdT/ziImnn\nlOSfgY9U1fvnuhaNN4NC2gkl+VXgApoxltvnuh6Nt8EuPSX5QJKbknx9C9uT5D1J1qW5seqAoWqR\ntFmSU2nusXi9IaE+BjujSPKbwE+AD1XVk6fZfhjwGppruU8H/ldVPX1qO0nS3BrsjKKqPkczWLcl\nR9CESFXVJcCeSR45VD2SpJmZy4nF9uK+NxBNtuu+P7VhkuNo7qLloQ996NOe+MQnzkqBkjRfXH75\n5T+qqqn35vSyQ8xAWVWrgdUAExMTtXbt2jmuSJJ2LElm/DHoubyP4kaaO2g3Wd6ukySNkbkMijXA\ny9pPPz2DZr6Z+112kiTNrcEuPSU5AzgIWNrOs/92mpk8qaqTaaaDPozmbtifAi8fqhZJ0swNFhRV\nddRWthfw6u3xXHfffTeTk5Ns3LjxftsWLVrE8uXLWbjQ72SRpJnYIQazt2ZycpLFixezzz77MDpR\naFWxYcMGJicn2XfffeewQknacc2LSQE3btzIkiVL7hMSAElYsmTJtGcakqR+5kVQAPcLia2tlyT1\nM2+CQpI0DINCktRp3gTFliY3dBp1SXpg5kVQLFq0iA0bNtwvFDZ96mnRokVzVJkk7fjmxcdjly9f\nzuTkJOvXr7/ftk33UUiSZmZeBMXChQu9T0KSBjIvLj1JkoZjUEiSOhkUkqROBoUkqZNBIUnqZFBI\nkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBI\nkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOg0aFEkOTXJtknVJ3jzN9kcn\nuTjJFUmuSnLYkPVIkrbdYEGRZAFwEvBcYCVwVJKVU5q9FTi7qvYHjgT+bqh6JEkzM+QZxYHAuqq6\nrqruAs4EjpjSpoCHtY/3AL43YD2SpBkYMij2Am4YWZ5s1406ATg6ySRwHvCa6Q6U5Lgka5OsXb9+\n/RC1SpK2YK4Hs48CPlhVy4HDgNOS3K+mqlpdVRNVNbFs2bJZL1KSdmZDBsWNwN4jy8vbdaNeAZwN\nUFVfAhYBSwesSZK0jYYMisuAFUn2TbIbzWD1miltvgscDJDkSTRB4bUlSRojgwVFVd0DHA+cD3yD\n5tNNVyc5McmqttkbgGOTfBU4AzimqmqomiRJ227XIQ9eVefRDFKPrnvbyONrgGcNWYMk6YGZ68Fs\nSdKYMygkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1Mmg\nkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1Mmg\nkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQYNiiSHJrk2ybok\nb95CmxcluSbJ1Uk+MmQ9kqRtt+tQB06yADgJ+G1gErgsyZqqumakzQrgz4FnVdUtSR4xVD2SpJkZ\n8oziQGBdVV1XVXcBZwJHTGlzLHBSVd0CUFU3DViPJGkGhgyKvYAbRpYn23Wj9gP2S/KFJJckOXS6\nAyU5LsnaJGvXr18/ULmSpOnM9WD2rsAK4CDgKOB9Sfac2qiqVlfVRFVNLFu2bJZLlKSdW6+gSPKx\nJM9Lsi3BciOw98jy8nbdqElgTVXdXVX/CnyLJjgkSWOi7wv/3wEvAb6d5K+SPKHHPpcBK5Lsm2Q3\n4EhgzZQ259KcTZBkKc2lqOt61iRJmgW9gqKqLqyq3wcOAL4DXJjki0lenmThFva5BzgeOB/4BnB2\nVV2d5MQkq9pm5wMbklwDXAy8qao2PLBfSZK0PaWq+jVMlgBHAy8FvgecDvw68MtVddBQBU41MTFR\na9euna2nk6R5IcnlVTUxk3173UeR5OPAE4DTgMOr6vvtprOS+KotSfNY3xvu3lNVF0+3YaYJJUna\nMfQdzF45+rHVJA9P8qqBapIkjZG+QXFsVd26aaG9k/rYYUqSJI2TvkGxIEk2LbTzOO02TEmSpHHS\nd4zi0zQD16e0y3/UrpMkzXN9g+LPaMLhle3yBcD7B6lIkjRWegVFVd0L/H37I0naifS9j2IF8N+B\nlcCiTeur6rED1SVJGhN9B7P/keZs4h7gOcCHgA8PVZQkaXz0DYoHV9VFNFN+XF9VJwDPG64sSdK4\n6DuYfWc7xfi3kxxPM1347sOVJUkaF33PKF4HPAR4LfA0mskB/2CooiRJ42OrZxTtzXUvrqo3Aj8B\nXj54VZKksbHVM4qq+jnNdOKSpJ1Q3zGKK5KsAT4K3LFpZVV9bJCqJEljo29QLAI2AL81sq4Ag0KS\n5rm+d2Y7LiFJO6m+d2b/I80ZxH1U1R9u94okSWOl76WnT4w8XgS8gOZ7syVJ81zfS0//e3Q5yRnA\n5wepSJI0VvrecDfVCuAR27MQSdJ46jtGcTv3HaP4Ac13VEiS5rm+l54WD12IJGk89br0lOQFSfYY\nWd4zyfOHK0uSNC76jlG8vapu27RQVbcCbx+mJEnSOOkbFNO16/vRWknSDqxvUKxN8u4kj2t/3g1c\nPmRhkqTx0DcoXgPcBZwFnAlsBF49VFGSpPHR91NPdwBvHrgWSdIY6vuppwuS7Dmy/PAk5w9XliRp\nXPS99LS0/aQTAFV1C96ZLUk7hb5BcW+SR29aSLIP08wmK0maf/p+xPUtwOeTfBYI8BvAcYNVJUka\nG30Hsz+dZIImHK4AzgV+NmRhkqTx0Hcw+z8CFwFvAN4InAac0GO/Q5Ncm2Rdki1+airJC5NUG0aS\npDHSd4zidcCvAtdX1XOA/YFbu3ZIsgA4CXgusBI4KsnKadotbo9/6TbULUmaJX2DYmNVbQRI8qCq\n+ibwhK3scyCwrqquq6q7aG7UO2Kadn8JvIPmJj5J0pjpGxST7X0U5wIXJPkn4Pqt7LMXcMPoMdp1\n/ybJAcDeVfXJrgMlOS7J2iRr169f37NkSdL20Hcw+wXtwxOSXAzsAXz6gTxxkl2AdwPH9Hj+1cBq\ngImJCT+WK0mzaJtngK2qz/ZseiOw98jy8nbdJouBJwOfSQLwi8CaJKuqau221iVJGsZMvzO7j8uA\nFUn2TbIbcCSwZtPGqrqtqpZW1T5VtQ9wCWBISNKYGSwoquoe4HjgfOAbwNlVdXWSE5OsGup5JUnb\n16BfPlRV5wHnTVn3ti20PWjIWiRJMzPkpSdJ0jxgUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKk\nTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKk\nTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKk\nTgaFJKmTQSFJ6mRQSJI6DRoUSQ5Ncm2SdUnePM32P01yTZKrklyU5DFD1iNJ2naDBUWSBcBJwHOB\nlcBRSVZOaXYFMFFVTwHOAf7HUPVIkmZmyDOKA4F1VXVdVd0FnAkcMdqgqi6uqp+2i5cAywesR5I0\nA0MGxV7ADSPLk+26LXkF8KnpNiQ5LsnaJGvXr1+/HUuUJG3NWAxmJzkamADeOd32qlpdVRNVNbFs\n2bLZLU6SdnK7DnjsG4G9R5aXt+vuI8khwFuAZ1fVnQPWI0magSHPKC4DViTZN8luwJHAmtEGSfYH\nTgFWVdVNA9YiSZqhwYKiqu4BjgfOB74BnF1VVyc5Mcmqttk7gd2Bjya5MsmaLRxOkjRHhrz0RFWd\nB5w3Zd3bRh4fMuTzS5IeuLEYzJYkjS+DQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0M\nCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0M\nCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0M\nCklSJ4NCktTJoJAkdRo0KJIcmuTaJOuSvHma7Q9Kcla7/dIk+wxZjyRp2w0WFEkWACcBzwVWAkcl\nWTml2SuAW6rq8cDfAO8Yqh5J0swMeUZxILCuqq6rqruAM4EjprQ5Aji1fXwOcHCSDFiTJGkb7Trg\nsfcCbhhZngSevqU2VXVPktuAJcCPRhslOQ44rl28M8nXB6l4x7OUKX21E7MvNrMvNrMvNnvCTHcc\nMii2m6paDawGSLK2qibmuKSxYF9sZl9sZl9sZl9slmTtTPcd8tLTjcDeI8vL23XTtkmyK7AHsGHA\nmiRJ22jIoLgMWJFk3yS7AUcCa6a0WQP8Qfv494B/rqoasCZJ0jYa7NJTO+ZwPHA+sAD4QFVdneRE\nYG1VrQH+ATgtyTrgZpow2ZrVQ9W8A7IvNrMvNrMvNrMvNptxX8Q38JKkLt6ZLUnqZFBIkjqNbVA4\n/cdmPfriT5Nck+SqJBclecxc1DkbttYXI+1emKSSzNuPRvbpiyQvav82rk7ykdmucbb0+B95dJKL\nk1zR/p8cNhd1Di3JB5LctKV7zdJ4T9tPVyU5oNeBq2rsfmgGv/8FeCywG/BVYOWUNq8CTm4fHwmc\nNdd1z2FfPAd4SPv4lTtzX7TtFgOfAy4BJua67jn8u1gBXAE8vF1+xFzXPYd9sRp4Zft4JfCdua57\noL74TeAA4Otb2H4Y8CkgwDOAS/scd1zPKJz+Y7Ot9kVVXVxVP20XL6G5Z2U+6vN3AfCXNPOGbZzN\n4mZZn744Fjipqm4BqKqbZrnG2dKnLwp4WPt4D+B7s1jfrKmqz9F8gnRLjgA+VI1LgD2TPHJrxx3X\noJhu+o+9ttSmqu4BNk3/Md/06YtRr6B5xzAfbbUv2lPpvavqk7NZ2Bzo83exH7Bfki8kuSTJobNW\n3ezq0xcnAEcnmQTOA14zO6WNnW19PQF2kCk81E+So4EJ4NlzXctcSLIL8G7gmDkuZVzsSnP56SCa\ns8zPJfnlqrp1TquaG0cBH6yqdyV5Js39W0+uqnvnurAdwbieUTj9x2Z9+oIkhwBvAVZV1Z2zVNts\n21pfLAaeDHwmyXdorsGumacD2n3+LiaBNVV1d1X9K/AtmuCYb/r0xSuAswGq6kvAIpoJA3c2vV5P\nphrXoHD6j8222hdJ9gdOoQmJ+XodGrbSF1V1W1Utrap9qmofmvGaVVU148nQxlif/5Fzac4mSLKU\n5lLUdbNZ5Czp0xffBQ4GSPIkmqBYP6tVjoc1wMvaTz89A7itqr6/tZ3G8tJTDTf9xw6nZ1+8E9gd\n+Gg7nv/dqlo1Z0UPpGdf7BR69sX5wL9Pcg3wc+BNVTXvzrp79sUbgPcl+ROage1j5uMbyyRn0Lw5\nWNqOx7wdWAhQVSfTjM8cBqwDfgq8vNdx52FfSZK2o3G99CRJGhMGhSSpk0EhSepkUEiSOhkUkqRO\nBoU0i5IclOQTc12HtC0MCklSJ4NCmkaSo5N8OcmVSU5JsiDJT5L8TfvdDhclWda2fWo76d5VST6e\n5OHt+scnuTDJV5N8Jcnj2sPvnuScJN9Mcvo8nfVY84hBIU3RTvHwYuBZVfVUmruafx94KM2dvr8E\nfJbmrleADwF/VlVPAb42sv50mmm+fwX4NWDTVAn7A6+n+V6ExwLPGvyXkh6AsZzCQ5pjBwNPAy5r\n3+w/GLgJuBc4q23zYeBjSfYA9qyqz7brT6WZSmUxsFdVfRygqjYCtMf7clVNtstXAvsAnx/+15Jm\nxqCQ7i/AqVX15/dZmfznKe1mOv/N6Oy+P8f/Q405Lz1J93cR8HtJHgGQ5Bfa7yHfhWamYoCXAJ+v\nqtuAW5L8Rrv+pcBnq+p2YDLJ89tjPCjJQ2b1t5C2E9/JSFNU1TVJ3gr83/bLkO4GXg3cARzYbruJ\nZhwDmunuT26D4Do2z8j5UuCUdhbTu4H/MIu/hrTdOHus1FOSn1TV7nNdhzTbvPQkSerkGYUkqZNn\nFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE7/H2wukO8ywOfsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzw3jVcOw7kX",
        "colab_type": "code",
        "outputId": "70d084ce-1295-45b7-aa57-f1b592da84ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "\n",
        "\n",
        "# first neural network with keras make predictions\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "# load the dataset\n",
        "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='tanh'))\n",
        "model.add(Dense(8, activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
        "# make class predictions with the model\n",
        "predictions = model.predict_classes(X)\n",
        "# summarize the first 5 cases\n",
        "for i in range(5):\n",
        "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}